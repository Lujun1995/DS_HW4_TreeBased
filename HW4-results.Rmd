---
title: "DS HW4 Tree Based Models"
author: "JunLu"
date: "4/16/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = F)
library(lasso2)
library(tidyverse)
data(Prostate)
library(rpart)
library(rpart.plot)
library(caret)
library(ranger)
library(gbm)
library(ISLR)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Problem 1

### a) Fit a regression tree

#### The lowest cross-validation error 


```{r}
ctrl = trainControl(method = "cv")
```

```{r, cache=TRUE}
set.seed(1) 

tree_fit = train(lpsa~., 
            data = Prostate,
            method = "rpart",
            tuneGrid = data.frame(cp =exp(seq(-8,-2, length = 20))),
            trControl = ctrl)

ggplot(tree_fit, highlight = TRUE)
```


```{r, cache=TRUE}
tree_fit$bestTune
tree_fit$finalModel$cptable
rpart.plot(tree_fit$finalModel)
```

The tree size corresponds to the lowest cross-validation error is 8

#### The 1 SE rule
```{r, cache=TRUE}
set.seed(1) 
tree_fit_2 = train(lpsa~., 
            data = Prostate,
            method = "rpart",
            tuneGrid = data.frame(cp =exp(seq(-8,-2, length = 20))),
            trControl = trainControl(method = "cv",
                                     number = 10,
                                     selectionFunction = "oneSE"))

ggplot(tree_fit_2, highlight = TRUE)
```

```{r, cache=TRUE}
tree_fit_2$finalModel$cptable
```

The tree size obtained using the 1 SE rule is 3.

The two tree sizes obtained by different selection functions are different.





### b) Choose one decision tree model

```{r, cache=TRUE}
resamp <- resamples(list(lowest_cv_error = tree_fit, 
                         one_se = tree_fit_2
                         ))
bwplot(resamp, metric = "RMSE")
```

I used tree size 3 as it has a similar performance with size 8 and it is simpler.




```{r, cache=TRUE}
rpart.plot(tree_fit_2$finalModel)
```

The first terminal node in the plot:
When the lcavol is smaller than -0.48 (firstly smaller than 2.5), the predicted value (or the mean of observations in this terminal node) is 0.6. This terminal node contains 9% training data observations.

### c) Bagging

```{r, cache=TRUE}
set.seed(1)

bagging.grid <- expand.grid(mtry = 8,
                       splitrule = "variance",
                       min.node.size = 1:30
                       )

bag_fit = train(lpsa~.,
                data = Prostate,
                method = "ranger",
                tuneGrid = bagging.grid,
                importance = "impurity",
                trControl = ctrl)

ggplot(bag_fit, highlight = T)


barplot(sort(ranger::importance(bag_fit$finalModel), 
             decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(
            colors =c("darkred","white","darkblue"))(19))
```

The lcavol is the most importance variable in this bagging model.

Importance:
lcavol > lweight > svi > pgg45 > age > lcp > lbph > gleason


### d) Random Forests
```{r, cache=TRUE}
set.seed(1)

rf.grid <- expand.grid(mtry = 1:6,
                       splitrule = "variance",
                       min.node.size = 1:30
                       )

rf_fit = train(lpsa~.,
                data = Prostate,
                method = "ranger",
                tuneGrid = rf.grid,
                importance = "impurity",
                trControl = ctrl)

ggplot(rf_fit, highlight = T)
```

```{r}
barplot(sort(ranger::importance(rf_fit$finalModel), 
             decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(
            colors = c("darkred","white","darkblue"))(19))
```

The lcavol is the most importance variable in this random forests model.

Importance:
lcavol > svi > lweight > lcp > pgg45 >  lbph > age > gleason


### e) Boosting 
```{r, cache=TRUE}
set.seed(1)
gbm.grid = expand.grid(
    n.trees = seq(1,5001, by = 500),
    interaction.depth = 1:10,
    shrinkage = c(0.001, 0.003, 0.005),
    n.minobsinnode = 1
    )

gbm_fit = train(lpsa~.,
                data = Prostate,
                method = "gbm",
                tuneGrid = gbm.grid,
                trControl = ctrl,
                verbose = FALSE)

ggplot(gbm_fit, highlight = T)
```

```{r, cache=TRUE}
summary(gbm_fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```

The lcavol is the most importance variable in this boosting model.

Importance:
lcavol > lweight > svi > lcp > pgg45 > age > lbph > gleason



### d) Compare Models
```{r, cache=TRUE}
resamp <- resamples(list(tree_fit = tree_fit, 
                         tree_fit_1SE = tree_fit_2,
                         bagging = bag_fit,
                         rondomforest = rf_fit,
                         boosting = gbm_fit
                         ))
a = bwplot(resamp, metric = "RMSE")
b = ggplot(resamp, metric = "RMSE") 

gridExtra::grid.arrange(a,b,ncol = 2,nrow = 1)
```

From the boxplots of RMSE in the cross-vaildation, we can see that ensemble methods (bagging, random forerst and boosting) have a better performance in the cross-vaildation than the simple decision tree model. Comparing means of RMSE of different models in the cross-vaildation, we choose the boosting model to predict PSA level as it has the lowest mean.


### Problem 2

#### a) Decision Tree
```{r, cache=TRUE}
data(OJ)
```

```{r}
set.seed(1)

train_ind <- sample(seq_len(nrow(OJ)), size = 800)

training <- OJ[train_ind, ]
test <- OJ[-train_ind, ]
```

```{r}
set.seed(1)
ctrl = trainControl(method = "repeatedcv",
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)

tree_fit_c = train(Purchase~.,
                 data = training,
                 method = "rpart",
                 tuneGrid = data.frame(cp = exp(seq(-15,0, by = 2))),
                 trControl = ctrl,
                 metric = "ROC"
                 )

plot(tree_fit_c, xTrans = function(x)log(x), xlab = "log(cp)")

ggplot(tree_fit_c, highlight = T)
```

```{r}
tree_fit_c$bestTune
tree_fit_c$finalModel$cptable
```

##### The plot of the final tree
```{r}
rpart.plot(tree_fit_c$finalModel)
```

```{r}
tree.pred = predict(tree_fit_c, newdata = test, type = "raw")

1 - sum(tree.pred == test$Purchase) / length(test$Purchase)
```

##### Test classification error rate
The tree size is 23. The test classification error rate is 19.26% for this tree model.

#### b)Random forests

```{r, cache=TRUE}
set.seed(1)
rf.grid = expand.grid(mtry = 2:7,
                      splitrule = "gini",
                      min.node.size = seq(20,120, by = 10))

rf_fit_c = train(Purchase~.,
                 data = training,
                 method = "ranger",
                 tuneGrid = rf.grid,
                 metric = "ROC",
                 trControl = ctrl,
                 importance = "impurity")

ggplot(rf_fit_c, highlight = T)
```

```{r, cache=TRUE}
barplot(sort(ranger::importance(rf_fit_c$finalModel), 
             decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(
            colors = c("darkred","white","darkblue"))(19))
```


```{r, cache=TRUE}
rf.pred = predict(rf_fit_c, newdata = test, type = "raw")

1 - sum(rf.pred == test$Purchase) / length(test$Purchase)
```

The test classification error rate is 17.04% for this tree model.

The loyalCH is the most importance variable in this boosting model.

The top 5 most important variables:
LoyalCH > StoreID > PriceDiff > ListPriceDiff > STORE 

#### c) Boosting

```{r, cache=TRUE}
set.seed(1)
gbm.grid = expand.grid(n.trees = seq(100, 600, by = 10),
                       interaction.depth = 2:6,
                       shrinkage = c(0.001, 0.003, 0.005),
                       n.minobsinnode = 1)

gbm_fit_c = train(Purchase~.,
                data = training,
                method = "gbm",
                trControl = ctrl,
                distribution = "bernoulli",
                metric = "ROC",
                tuneGrid = gbm.grid,
                verbose = F
                )

ggplot(gbm_fit_c, highlight = T)
```


```{r, cache=TRUE}
summary(gbm_fit_c$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```


```{r, cache=TRUE}
gbm.pred = predict(gbm_fit_c, newdata = test, type = "raw")

1 - sum(gbm.pred == test$Purchase) / length(test$Purchase)
```

The test classification error rate is 18.15% for this boosting model.

The loyalCH is the most importance variable in this boosting model. 
The top 5 most important variables: LoyalCH > StoreID > PriceDiff > ListPriceDiff > STORE

